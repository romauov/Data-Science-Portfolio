{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "da6ce154-3c06-4f97-9749-ea6dcb38e94a",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Spark и RDD"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e636fdec-16af-4d76-a894-55fe6bf74674",
   "metadata": {},
   "source": [
    "Инициализируйте объект SparkContext. Укажите параметр appName равный 'appName'. Создайте переменную weather_entry (англ. «запись о погоде»), в которой сохраните RDD с такими элементами:\n",
    "* дата заказа — 2009-01-01;\n",
    "* самая низкая температура воздуха в этот день (°C) — 15.1;\n",
    "* самая высокая температура воздуха в этот день (°C) — 26.1.\n",
    "\n",
    "Выведите на экран содержимое RDD. Для этого вызовите метод take() (англ. «взять»). Посмотрите в документации, как он работает."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "952cfb2a-ad02-4d96-ac27-84481e236f82",
   "metadata": {},
   "source": [
    "```python \n",
    "from pyspark import SparkContext\n",
    "\n",
    "sc = SparkContext(appName='appName')\n",
    "weather_entry = sc.parallelize(['2009-01-01', 15.1, 26.1])\n",
    "print(weather_entry.take(3))\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff16d720-7956-4847-987d-7dc9f06db13d",
   "metadata": {},
   "source": [
    "```\n",
    "[Stage 0:>        (0 + 1) / 1]\n",
    "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        \n",
    "['2009-01-01', 15.1, 26.1]\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f39af2f5-0a13-4fa9-9e6a-200d415f077b",
   "metadata": {},
   "source": [
    "## Создание датафреймов"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e75158f6-fd42-4869-87a9-46dec47dfc9c",
   "metadata": {},
   "source": [
    "1.Загрузите датафрейм из файла /datasets/pickups_terminal_5.csv. Посмотрите в документации, как работает функция show(). Напечайте на экране пять строк из датафрейма."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d02ca5b5-c9c5-4529-a469-4a81a538b89c",
   "metadata": {},
   "source": [
    "```python\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "APP_NAME = \"DataFrames\"\n",
    "SPARK_URL = \"local[*]\"\n",
    "\n",
    "spark = SparkSession.builder.appName(APP_NAME) \\\n",
    "        .config('spark.ui.showConsoleProgress', 'false') \\\n",
    "        .getOrCreate()\n",
    "\n",
    "taxi = spark.read.load('/datasets/pickups_terminal_5.csv', format='csv', header='true', inferSchema='true')\n",
    "taxi.show(5)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31177078-206c-4d6a-ad60-9a6f142b7d84",
   "metadata": {},
   "source": [
    "```\n",
    "+-------------------+----+------+-------+\n",
    "|               date|hour|minute|pickups|\n",
    "+-------------------+----+------+-------+\n",
    "|2009-01-01 00:00:00|   0|     0|   24.0|\n",
    "|2009-01-01 00:00:00|   0|    30|   35.0|\n",
    "|2009-01-01 00:00:00|   1|     0|   25.0|\n",
    "|2009-01-01 00:00:00|   1|    30|   25.0|\n",
    "|2009-01-01 00:00:00|   2|     0|   16.0|\n",
    "+-------------------+----+------+-------+\n",
    "only showing top 5 rows\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2938b48c-fb6f-44ec-bcb4-b31020d98362",
   "metadata": {},
   "source": [
    "2. Методом show() размер датасета не получить. Найдите в документации функцию, которая посчитает количество строк. Напечайте результат на экране."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d480fc06-b1cb-4163-bdb7-9228a3db1c54",
   "metadata": {},
   "source": [
    "```python\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "APP_NAME = \"DataFrames\"\n",
    "SPARK_URL = \"local[*]\"\n",
    "\n",
    "spark = SparkSession.builder.appName(APP_NAME) \\\n",
    "        .config('spark.ui.showConsoleProgress', 'false') \\\n",
    "        .getOrCreate()\n",
    "\n",
    "taxi = spark.read.load('/datasets/pickups_terminal_5.csv', \n",
    "                       format='csv', header='true', inferSchema='true')\n",
    "\n",
    "print(taxi.count())\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e9328d3-68a7-47ee-bc3b-36c83ca96924",
   "metadata": {},
   "source": [
    "```\n",
    "128974\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08b9c027-94db-4e9b-b3e1-a0ffa3479865",
   "metadata": {},
   "source": [
    "3. Выберите из датафрейма только столбцы с датами, часами и минутами в указанном порядке. Выбор подмножества столбцов выполняется так же, как в Pandas. \n",
    "\n",
    "Напечатайте на экране пять строк получившейся таблицы."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d65d4ea-900e-493d-a1eb-b70e608eaf68",
   "metadata": {},
   "source": [
    "```python\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "APP_NAME = \"DataFrames\"\n",
    "SPARK_URL = \"local[*]\"\n",
    "\n",
    "spark = SparkSession.builder.appName(APP_NAME) \\\n",
    "        .config('spark.ui.showConsoleProgress', 'false') \\\n",
    "        .getOrCreate()\n",
    "\n",
    "taxi = spark.read.load('/datasets/pickups_terminal_5.csv', \n",
    "                       format='csv', header='true', inferSchema='true')\n",
    "\n",
    "print(taxi[['date', 'hour', 'minute']].show(5))\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e677b48-640c-4420-a120-eafcd6e04d00",
   "metadata": {},
   "source": [
    "```\n",
    "+-------------------+----+------+\n",
    "|               date|hour|minute|\n",
    "+-------------------+----+------+\n",
    "|2009-01-01 00:00:00|   0|     0|\n",
    "|2009-01-01 00:00:00|   0|    30|\n",
    "|2009-01-01 00:00:00|   1|     0|\n",
    "|2009-01-01 00:00:00|   1|    30|\n",
    "|2009-01-01 00:00:00|   2|     0|\n",
    "+-------------------+----+------+\n",
    "only showing top 5 rows\n",
    "\n",
    "None\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1facd8a8-c1e1-4ea4-8d74-865affc9c5e1",
   "metadata": {},
   "source": [
    "## Обработка пропущенных значений"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6515dde-c010-4724-a111-6e8087105fe6",
   "metadata": {},
   "source": [
    "1. Удалите из датафрейма пропущенные значения. Затем напечатайте на экране количество строк в датафрейме."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "848e2ca8-3826-4226-927a-3f4e8c395beb",
   "metadata": {},
   "source": [
    "```python\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "APP_NAME = \"DataFrames\"\n",
    "SPARK_URL = \"local[*]\"\n",
    "\n",
    "spark = SparkSession.builder.appName(APP_NAME) \\\n",
    "        .config('spark.ui.showConsoleProgress', 'false') \\\n",
    "        .getOrCreate()\n",
    "\n",
    "taxi = spark.read.load('/datasets/pickups_terminal_5.csv', \n",
    "                       format='csv', header='true', inferSchema='true')\n",
    "\n",
    "taxi = taxi.dropna()\n",
    "print(taxi.count())\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f1a7cab-8441-4658-86db-bd4a56fd14b4",
   "metadata": {},
   "source": [
    "```\n",
    "128969\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0885115a-60d4-4366-b3a2-94a16a17b1fe",
   "metadata": {},
   "source": [
    "2. Заполните пропущенные значения в датафрейме нулями. Функцией describe() выведите на экран результаты, чтобы убедиться в корректности заполнения значений."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e452074-2675-4a99-bee8-d3eeb3e37f6a",
   "metadata": {},
   "source": [
    "```python\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "APP_NAME = \"DataFrames\"\n",
    "SPARK_URL = \"local[*]\"\n",
    "\n",
    "spark = SparkSession.builder.appName(APP_NAME) \\\n",
    "        .config('spark.ui.showConsoleProgress', 'false') \\\n",
    "        .getOrCreate()\n",
    "\n",
    "taxi = spark.read.load('/datasets/pickups_terminal_5.csv', \n",
    "                       format='csv', header='true', inferSchema='true')\n",
    "taxi = taxi.fillna(0)\n",
    "print(taxi.describe().show())\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff5c9e93-8ef7-4077-a84e-99eca5ff269d",
   "metadata": {},
   "source": [
    "```\n",
    "+-------+------------------+------------------+------------------+\n",
    "|summary|              hour|            minute|           pickups|\n",
    "+-------+------------------+------------------+------------------+\n",
    "|  count|            128974|            128974|            128974|\n",
    "|   mean|11.566509529052366|15.004419495402175| 29.00832725975778|\n",
    "| stddev| 6.908556452594711|15.000057500526209|22.449669931429067|\n",
    "|    min|                 0|                 0|               0.0|\n",
    "|    max|                23|                30|             310.0|\n",
    "+-------+------------------+------------------+------------------+\n",
    "\n",
    "None\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab9c0c3f-6581-4f55-874b-d579e10642e9",
   "metadata": {},
   "source": [
    "## SQL-запросы в датафреймах"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15d30633-9739-4c4a-ada5-67a2eb89f829",
   "metadata": {},
   "source": [
    "1. Изучите статистические выбросы. В переменной result сохраните результат запроса, который выберет даты с числом заказов такси у терминала №5, расположив их от большего к меньшему. Выведите на экран первые пять строк, используя функцию show."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c63f8144-145d-4c90-aeef-f8266f07f050",
   "metadata": {},
   "source": [
    "```python\n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "APP_NAME = \"DataFrames\"\n",
    "SPARK_URL = \"local[*]\"\n",
    "\n",
    "spark = SparkSession.builder.appName(APP_NAME) \\\n",
    "        .config('spark.ui.showConsoleProgress', 'false') \\\n",
    "        .getOrCreate()\n",
    "\n",
    "taxi = spark.read.load('/datasets/pickups_terminal_5.csv', \n",
    "                       format='csv', header='true', inferSchema='true')\n",
    "\n",
    "taxi = taxi.fillna(0)\n",
    "\n",
    "taxi.registerTempTable(\"taxi\")\n",
    "\n",
    "result = spark.sql(\"SELECT * FROM taxi ORDER BY pickups DESC\")\n",
    "print(result.show(5))\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea05f61e-250f-446e-82fb-922d60224520",
   "metadata": {},
   "source": [
    "```\n",
    "+-------------------+----+------+-------+\n",
    "|               date|hour|minute|pickups|\n",
    "+-------------------+----+------+-------+\n",
    "|2015-11-01 00:00:00|   1|    30|  310.0|\n",
    "|2010-09-23 00:00:00|  22|    30|  288.0|\n",
    "|2012-03-07 00:00:00|  21|     0|  268.0|\n",
    "|2011-03-02 00:00:00|  20|    30|  264.0|\n",
    "|2011-03-02 00:00:00|  18|    30|  263.0|\n",
    "+-------------------+----+------+-------+\n",
    "only showing top 5 rows\n",
    "\n",
    "None\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3663c6e-d278-488e-ba2e-57943f7b49a5",
   "metadata": {},
   "source": [
    "2. Найдите все даты, на которые пришлось более 200 заказов такси за любой период в 30 минут в этот день. Напечатайте на экране количество таких дней, сохранив результат в переменную result."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6031f5b5-44e1-497a-b484-da8a203255c2",
   "metadata": {},
   "source": [
    "```python\n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "APP_NAME = \"DataFrames\"\n",
    "SPARK_URL = \"local[*]\"\n",
    "\n",
    "spark = SparkSession.builder.appName(APP_NAME) \\\n",
    "        .config('spark.ui.showConsoleProgress', 'false') \\\n",
    "        .getOrCreate()\n",
    "\n",
    "taxi = spark.read.load('/datasets/pickups_terminal_5.csv', \n",
    "                       format='csv', header='true', inferSchema='true')\n",
    "\n",
    "taxi = taxi.fillna(0)\n",
    "\n",
    "taxi.registerTempTable(\"taxi\")\n",
    "\n",
    "result = spark.sql(\"SELECT COUNT(DISTINCT date) FROM taxi WHERE pickups > 200\")\n",
    "print(result.show()) \n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82ae10c2-6ce3-46c5-bbfb-163480d680e7",
   "metadata": {},
   "source": [
    "```\n",
    "+--------------------+\n",
    "|count(DISTINCT date)|\n",
    "+--------------------+\n",
    "|                  21|\n",
    "+--------------------+\n",
    "\n",
    "None\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2cc1a02-0ca8-444f-a986-3cae5c8b22b4",
   "metadata": {},
   "source": [
    "## GroupBy в PySpark"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e28a34eb-8970-4532-9bc6-b758e5dfe440",
   "metadata": {},
   "source": [
    "1. Сгруппируйте записи по месяцам. По каждому месяцу рассчитайте среднее количество заказов. \n",
    "\n",
    "Напечатайте на экране таблицу с месяцами и средним количеством заказов по убыванию."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a783923f-ff4e-4d5b-a552-9a4cd5bea7ba",
   "metadata": {},
   "source": [
    "```python\n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "APP_NAME = \"DataFrames\"\n",
    "SPARK_URL = \"local[*]\"\n",
    "\n",
    "spark = SparkSession.builder.appName(APP_NAME) \\\n",
    "        .config('spark.ui.showConsoleProgress', 'false') \\\n",
    "        .getOrCreate()\n",
    "\n",
    "taxi = spark.read.load('/datasets/pickups_terminal_5.csv', \n",
    "                       format='csv', header='true', inferSchema='true')\n",
    "\n",
    "taxi = taxi.fillna(0)\n",
    "\n",
    "taxi.registerTempTable(\"taxi\")\n",
    "\n",
    "result = spark.sql('SELECT EXTRACT(MONTH FROM date), AVG(pickups) '\n",
    "                   'FROM taxi '\n",
    "                   'GROUP BY EXTRACT(MONTH FROM date) '\n",
    "                   'ORDER BY AVG(pickups) DESC')\n",
    "print(result.show()) \n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ab902d7-0b80-4fb3-ae72-809f5db16616",
   "metadata": {},
   "source": [
    "```\n",
    "+-------------------------+------------------+\n",
    "|month(CAST(date AS DATE))|      avg(pickups)|\n",
    "+-------------------------+------------------+\n",
    "|                        3| 34.61413319776309|\n",
    "|                       10|31.492839171666343|\n",
    "|                        2|29.856671982987773|\n",
    "|                        5| 29.81593638978176|\n",
    "|                        4|29.313725490196077|\n",
    "|                        9|29.158446485623003|\n",
    "|                       11|28.860367558929283|\n",
    "|                        1|  28.5473244004438|\n",
    "|                        6| 27.03835736129314|\n",
    "|                        7| 26.45983005021244|\n",
    "|                       12| 26.45916884626562|\n",
    "|                        8| 25.88592750533049|\n",
    "+-------------------------+------------------+\n",
    "\n",
    "None\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb4a9af7-2951-414b-81a5-c44b628a4b41",
   "metadata": {},
   "source": [
    "2. Вычислите среднее количество заказов за каждый час. Затем отсортируйте данные по убыванию. \n",
    "\n",
    "Выведите самые загруженные 10 часов и среднее количество заказов такси в эти часы."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bfb7809-3b40-4e83-b0c1-6068239d3c54",
   "metadata": {},
   "source": [
    "```python\n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "APP_NAME = \"DataFrames\"\n",
    "SPARK_URL = \"local[*]\"\n",
    "\n",
    "spark = SparkSession.builder.appName(APP_NAME) \\\n",
    "        .config('spark.ui.showConsoleProgress', 'false') \\\n",
    "        .getOrCreate()\n",
    "\n",
    "taxi = spark.read.load('/datasets/pickups_terminal_5.csv', \n",
    "                       format='csv', header='true', inferSchema='true')\n",
    "\n",
    "taxi = taxi.fillna(0)\n",
    "\n",
    "taxi.registerTempTable(\"taxi\")\n",
    "\n",
    "result = spark.sql('SELECT hour, AVG(pickups) '\n",
    "                   'FROM taxi '\n",
    "                   'GROUP BY hour '\n",
    "                   'ORDER BY AVG(pickups) DESC')\n",
    "print(result.show(10)) \n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b76cc59d-3b5f-4652-b16a-d1e79ec1f60e",
   "metadata": {},
   "source": [
    "```\n",
    "+----+------------------+\n",
    "|hour|      avg(pickups)|\n",
    "+----+------------------+\n",
    "|   8| 48.98208348725527|\n",
    "|   9| 45.74220335855324|\n",
    "|  18|45.131967515688444|\n",
    "|  19| 40.18456995201181|\n",
    "|  17| 37.68493909191584|\n",
    "|  12| 36.91678966789668|\n",
    "|  10|36.391031555637575|\n",
    "|  14|35.965867158671585|\n",
    "|   7| 35.93711855002774|\n",
    "|  13| 35.34939091915836|\n",
    "+----+------------------+\n",
    "only showing top 10 rows\n",
    "\n",
    "None\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45c24f5a-28ca-4013-a225-172eb4dfb795",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
